{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ictericia\n"
      ],
      "metadata": {
        "id": "Qoo8Esngx7PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "with open('dados.json', 'r') as f:\n",
        "    dados = json.load(f)\n",
        "\n",
        "# Filtro conforme suas regras\n",
        "dados_filtrados = [d for d in dados if (d[\"grau_ictericia\"] != \"estavel\") or (d[\"grau_ictericia\"] == d[\"grau_cianose\"])]\n",
        "\n",
        "X = np.array([d[\"rgb_ant\"] + d[\"rgb_atu\"] for d in dados_filtrados], dtype=np.float32)\n",
        "y = np.array([d[\"grau_ictericia\"] for d in dados_filtrados])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "CeFCEw9JwnRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Configura√ß√£o do modelo com par√¢metros otimizados\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=150,       # N√∫mero de √°rvores\n",
        "    max_depth=7,           # Profundidade m√°xima\n",
        "    min_samples_split=5,    # M√≠nimo de amostras para dividir um n√≥\n",
        "    class_weight='balanced', # Balanceamento autom√°tico de classes\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "BhaGTH824Pkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Previs√µes\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# M√©tricas\n",
        "print(\"üìä Relat√≥rio de Classifica√ß√£o:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "print(\"\\nüìä Matriz de Confus√£o:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "u3YJFwBe4UFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Extrai import√¢ncia das features\n",
        "importances = rf_clf.feature_importances_\n",
        "features = ['R_ant', 'G_ant', 'B_ant', 'R_atu', 'G_atu', 'B_atu']\n",
        "\n",
        "# Cria DataFrame para visualiza√ß√£o\n",
        "df_importances = pd.DataFrame({'Feature': features, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(df_importances['Feature'], df_importances['Importance'], color='skyblue')\n",
        "plt.xlabel('Import√¢ncia Relativa')\n",
        "plt.title('Import√¢ncia das Features no Modelo')\n",
        "plt.gca().invert_yaxis()  # Mostra a feature mais importante no topo\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vZF8PL4ZzxDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados novos (substitua com seus valores reais)\n",
        "novo_dado = np.array([[180, 150, 140, 160, 120, 90]])  # Formato: [R_ant, G_ant, B_ant, R_atu, G_atu, B_atu]\n",
        "\n",
        "# Pr√©-processamento\n",
        "novo_dado_scaled = scaler.transform(novo_dado)\n",
        "\n",
        "# Previs√£o\n",
        "previsao = rf_clf.predict(novo_dado_scaled)\n",
        "probabilidades = rf_clf.predict_proba(novo_dado_scaled)\n",
        "\n",
        "print(f\"\\nüîÆ Previs√£o para novo dado: {previsao[0]}\")\n",
        "print(\"Probabilidades por classe:\")\n",
        "for classe, prob in zip(rf_clf.classes_, probabilidades[0]):\n",
        "    print(f\"{classe}: {prob:.2%}\")\n",
        "\n",
        "\n",
        "novo_dado = np.array([[160, 104, 50, 160, 104, 50]])  # Formato: [R_ant, G_ant, B_ant, R_atu, G_atu, B_atu]\n",
        "\n",
        "# Pr√©-processamento\n",
        "novo_dado_scaled = scaler.transform(novo_dado)\n",
        "\n",
        "# Previs√£o\n",
        "previsao = rf_clf.predict(novo_dado_scaled)\n",
        "probabilidades = rf_clf.predict_proba(novo_dado_scaled)\n",
        "\n",
        "print(f\"\\nüîÆ Previs√£o para novo dado: {previsao[0]}\")\n",
        "print(\"Probabilidades por classe:\")\n",
        "for classe, prob in zip(rf_clf.classes_, probabilidades[0]):\n",
        "    print(f\"{classe}: {prob:.2%}\")\n"
      ],
      "metadata": {
        "id": "liNw8UcP6n9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Treinamento do modelo\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Salvando o modelo em um arquivo\n",
        "joblib.dump(rf_clf, 'rf-ictericia.pkl')"
      ],
      "metadata": {
        "id": "rzxv--NLoXIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cianose"
      ],
      "metadata": {
        "id": "sKhc6XVOx1LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Carrega e filtra os dados\n",
        "with open('dados.json', 'r') as f:\n",
        "    dados = json.load(f)\n",
        "\n",
        "# Filtro espec√≠fico para cianose (modifique conforme sua necessidade)\n",
        "dados_filtrados = [d for d in dados if d[\"grau_cianose\"] != \"nenhuma\"]  # Exemplo: remove casos sem cianose\n",
        "\n",
        "# Prepara os dados\n",
        "X = np.array([d[\"rgb_ant\"] + d[\"rgb_atu\"] for d in dados_filtrados], dtype=np.float32)\n",
        "y_cianose = np.array([d[\"grau_cianose\"] for d in dados_filtrados])  # R√≥tulos de cianose\n",
        "\n",
        "# Normaliza√ß√£o e divis√£o\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_cianose, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "7Lm2S_jTxuUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Configura√ß√£o otimizada para cianose\n",
        "rf_cianose = RandomForestClassifier(\n",
        "    n_estimators=200,       # Aumentamos o n√∫mero de √°rvores\n",
        "    max_depth=7,\n",
        "    min_samples_split=3,    # Mais sens√≠vel para padr√µes sutis de cianose\n",
        "    class_weight='balanced', # Crucial para cianose que costuma ser mais rara\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_cianose.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1A5qtbF2z4yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Previs√µes\n",
        "y_pred = rf_cianose.predict(X_test)\n",
        "\n",
        "# M√©tricas detalhadas\n",
        "print(\"üìä Relat√≥rio de Classifica√ß√£o para Cianose:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Matriz de confus√£o visual\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=rf_cianose.classes_,\n",
        "            yticklabels=rf_cianose.classes_)\n",
        "plt.title('Matriz de Confus√£o - Cianose')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.xlabel('Previsto')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f14_G9pEBUp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An√°lise espec√≠fica para padr√µes de cianose\n",
        "importances = rf_cianose.feature_importances_\n",
        "features = ['R_ant', 'G_ant', 'B_ant', 'R_atu', 'G_atu', 'B_atu']\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "}).sort_values('Importance', ascending=False).plot.barh(x='Feature', y='Importance', color='darkblue')\n",
        "plt.title('Import√¢ncia das Features para Cianose')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jiw8bhMSBWCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_cianose(rgb_ant, rgb_atu):\n",
        "    \"\"\"Fun√ß√£o completa para previs√£o de cianose\"\"\"\n",
        "    # Pr√©-processamento\n",
        "    novo_dado = np.array(rgb_ant + rgb_atu).reshape(1, -1)\n",
        "    novo_dado_scaled = scaler.transform(novo_dado)\n",
        "\n",
        "    # Previs√£o\n",
        "    grau = rf_cianose.predict(novo_dado_scaled)[0]\n",
        "    probas = rf_cianose.predict_proba(novo_dado_scaled)[0]\n",
        "\n",
        "    # Resultado formatado\n",
        "    print(f\"\\nüîµ Resultado para Cianose:\")\n",
        "    print(f\"Grau previsto: {grau}\")\n",
        "    print(\"Probabilidades:\")\n",
        "    for classe, prob in zip(rf_cianose.classes_, probas):\n",
        "        print(f\"‚Ä¢ {classe}: {prob:.1%}\")\n",
        "\n",
        "    return grau\n",
        "\n",
        "# Exemplo de uso:\n",
        "predict_cianose([184, 176, 172], [150, 127, 139])  # Substitua com valores reais\n",
        "\n",
        "predict_cianose([160, 104, 50], [160, 104, 50])  # Substitua com valores reais"
      ],
      "metadata": {
        "id": "qshB-ieJBdBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Treinamento do modelo\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Salvando o modelo em um arquivo\n",
        "joblib.dump(rf_cianose, 'rf-cianose.pkl')"
      ],
      "metadata": {
        "id": "36Jx8HaJoCpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}